#. TRANSLATORS: def String.pad_trailing(string, count, padding \\ [" "])
#: lib/string.ex:947 
msgid ""
"Returns a new string padded with a trailing filler\n"
"which is made of elements from the `padding`.\n"
"\n"
"Passing a list of strings as `padding` will take one element of the list\n"
"for every missing entry. If the list is shorter than the number of inserts,\n"
"the filling will start again from the beginning of the list.\n"
"Passing a string `padding` is equivalent to passing the list of graphemes in it.\n"
"If no `padding` is given, it defaults to whitespace.\n"
"\n"
"When `count` is less than or equal to the length of `string`,\n"
"given `string` is returned.\n"
"\n"
"Raises `ArgumentError` if the given `padding` contains non-string element.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.pad_trailing(\"abc\", 5)\n"
"    \"abc  \"\n"
"\n"
"    iex> String.pad_trailing(\"abc\", 4, \"12\")\n"
"    \"abc1\"\n"
"\n"
"    iex> String.pad_trailing(\"abc\", 6, \"12\")\n"
"    \"abc121\"\n"
"\n"
"    iex> String.pad_trailing(\"abc\", 5, [\"1\", \"23\"])\n"
"    \"abc123\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_float(string)
#: lib/string.ex:1882 
msgid ""
"Returns a float whose text representation is `string`.\n"
"\n"
"`string` must be the string representation of a float.\n"
"If a string representation of an integer wants to be used,\n"
"then `Float.parse/1` should be used instead,\n"
"otherwise an argument error will be raised.\n"
"\n"
"Inlined by the compiler.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.to_float(\"2.2017764e+0\")\n"
"    2.2017764\n"
"\n"
"    iex> String.to_float(\"3.0\")\n"
"    3.0\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.reverse(string)
#: lib/string.ex:1107 
msgid ""
"Reverses the graphemes in given string.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.reverse(\"abcd\")\n"
"    \"dcba\"\n"
"\n"
"    iex> String.reverse(\"hello world\")\n"
"    \"dlrow olleh\"\n"
"\n"
"    iex> String.reverse(\"hello ∂og\")\n"
"    \"go∂ olleh\"\n"
"\n"
"Keep in mind reversing the same string twice does\n"
"not necessarily yield the original string:\n"
"\n"
"    iex> \"̀e\"\n"
"    \"̀e\"\n"
"    iex> String.reverse(\"̀e\")\n"
"    \"è\"\n"
"    iex> String.reverse String.reverse(\"̀e\")\n"
"    \"è\"\n"
"\n"
"In the first example the accent is before the vowel, so\n"
"it is considered two graphemes. However, when you reverse\n"
"it once, you have the vowel followed by the accent, which\n"
"becomes one grapheme. Reversing it again will keep it as\n"
"one single grapheme.\n"
msgstr ""
#. TRANSLATORS: def String.next_grapheme_size(string)
#: lib/string.ex:1366 
msgid ""
"Returns the size of the next grapheme.\n"
"\n"
"The result is a tuple with the next grapheme size and\n"
"the remainder of the string or `nil` in case the string\n"
"reached its end.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.next_grapheme_size(\"olá\")\n"
"    {1, \"lá\"}\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.splitter(string, pattern, options \\ [])
#: lib/string.ex:371 
msgid ""
"Returns an enumerable that splits a string on demand.\n"
"\n"
"This is in contrast to `split/3` which splits all\n"
"the string upfront.\n"
"\n"
"Note splitter does not support regular expressions\n"
"(as it is often more efficient to have the regular\n"
"expressions traverse the string at once than in\n"
"multiple passes).\n"
"\n"
"## Options\n"
"\n"
"  * :trim - when `true`, does not emit empty patterns\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.splitter(\"1,2 3,4 5,6 7,8,...,99999\", [\" \", \",\"]) |> Enum.take(4)\n"
"    [\"1\", \"2\", \"3\", \"4\"]\n"
"\n"
"    iex> String.splitter(\"abcd\", \"\") |> Enum.take(10)\n"
"    [\"a\", \"b\", \"c\", \"d\", \"\"]\n"
"\n"
"    iex> String.splitter(\"abcd\", \"\", trim: true) |> Enum.take(10)\n"
"    [\"a\", \"b\", \"c\", \"d\"]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.last(string)
#: lib/string.ex:1403 
msgid ""
"Returns the last grapheme from a UTF-8 string,\n"
"`nil` if the string is empty.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.last(\"elixir\")\n"
"    \"r\"\n"
"\n"
"    iex> String.last(\"եոգլի\")\n"
"    \"ի\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.normalize(string, form)
#: lib/string.ex:512 
msgid ""
"Converts all characters in `string` to Unicode normalization\n"
"form identified by `form`.\n"
"\n"
"## Forms\n"
"\n"
"The supported forms are:\n"
"\n"
"  * `:nfd` - Normalization Form Canonical Decomposition.\n"
"    Characters are decomposed by canonical equivalence, and\n"
"    multiple combining characters are arranged in a specific\n"
"    order.\n"
"\n"
"  * `:nfc` - Normalization Form Canonical Composition.\n"
"    Characters are decomposed and then recomposed by canonical equivalence.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.normalize(\"yêṩ\", :nfd)\n"
"    \"yêṩ\"\n"
"\n"
"    iex> String.normalize(\"leña\", :nfc)\n"
"    \"leña\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.ends_with?(string, suffixes)
#: lib/string.ex:1679 
msgid ""
"Returns `true` if `string` ends with any of the suffixes given.\n"
"\n"
"`suffixes` can be either a single suffix or a list of suffixes.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.ends_with? \"language\", \"age\"\n"
"    true\n"
"    iex> String.ends_with? \"language\", [\"youth\", \"age\"]\n"
"    true\n"
"    iex> String.ends_with? \"language\", [\"youth\", \"elixir\"]\n"
"    false\n"
"\n"
"An empty suffix will always match:\n"
"\n"
"    iex> String.ends_with? \"language\", \"\"\n"
"    true\n"
"    iex> String.ends_with? \"language\", [\"\", \"other\"]\n"
"    true\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.upcase(binary)
#: lib/string.ex:540 
msgid ""
"Converts all characters in the given string to uppercase.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.upcase(\"abcd\")\n"
"    \"ABCD\"\n"
"\n"
"    iex> String.upcase(\"ab 123 xpto\")\n"
"    \"AB 123 XPTO\"\n"
"\n"
"    iex> String.upcase(\"olá\")\n"
"    \"OLÁ\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.capitalize(string)
#: lib/string.ex:576 
msgid ""
"Converts the first character in the given string to\n"
"uppercase and the remainder to lowercase.\n"
"\n"
"This relies on the titlecase information provided\n"
"by the Unicode Standard. Note this function makes\n"
"no attempt to capitalize all words in the string\n"
"(usually known as titlecase).\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.capitalize(\"abcd\")\n"
"    \"Abcd\"\n"
"\n"
"    iex> String.capitalize(\"ﬁn\")\n"
"    \"Fin\"\n"
"\n"
"    iex> String.capitalize(\"olá\")\n"
"    \"Olá\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.slice(string, range)
#: lib/string.ex:1545 
msgid ""
"Returns a substring from the offset given by the start of the\n"
"range to the offset given by the end of the range.\n"
"\n"
"If the start of the range is not a valid offset for the given\n"
"string or if the range is in reverse order, returns `\"\"`.\n"
"\n"
"If the start or end of the range is negative, the whole string\n"
"is traversed first in order to convert the negative indices into\n"
"positive ones.\n"
"\n"
"Remember this function works with Unicode graphemes and considers\n"
"the slices to represent grapheme offsets. If you want to split\n"
"on raw bytes, check `Kernel.binary_part/3` instead.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.slice(\"elixir\", 1..3)\n"
"    \"lix\"\n"
"\n"
"    iex> String.slice(\"elixir\", 1..10)\n"
"    \"lixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", 10..3)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"elixir\", -4..-1)\n"
"    \"ixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", 2..-1)\n"
"    \"ixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", -4..6)\n"
"    \"ixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", -1..-4)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"elixir\", -10..-7)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"a\", 0..1500)\n"
"    \"a\"\n"
"\n"
"    iex> String.slice(\"a\", 1..1500)\n"
"    \"\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.first(string)
#: lib/string.ex:1382 
msgid ""
"Returns the first grapheme from a UTF-8 string,\n"
"`nil` if the string is empty.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.first(\"elixir\")\n"
"    \"e\"\n"
"\n"
"    iex> String.first(\"եոգլի\")\n"
"    \"ե\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.chunk(string, trait)
#: lib/string.ex:1261 
msgid ""
"Splits the string into chunks of characters that share a common trait.\n"
"\n"
"The trait can be one of two options:\n"
"\n"
"  * `:valid` - the string is split into chunks of valid and invalid\n"
"    character sequences\n"
"\n"
"  * `:printable` - the string is split into chunks of printable and\n"
"    non-printable character sequences\n"
"\n"
"Returns a list of binaries each of which contains only one kind of\n"
"characters.\n"
"\n"
"If the given string is empty, an empty list is returned.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.chunk(<<?a, ?b, ?c, 0>>, :valid)\n"
"    [\"abc\\0\"]\n"
"\n"
"    iex> String.chunk(<<?a, ?b, ?c, 0, 0x0FFFF::utf8>>, :valid)\n"
"    [\"abc\\0\", <<0x0FFFF::utf8>>]\n"
"\n"
"    iex> String.chunk(<<?a, ?b, ?c, 0, 0x0FFFF::utf8>>, :printable)\n"
"    [\"abc\", <<0, 0x0FFFF::utf8>>]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.pad_leading(string, count, padding \\ [" "])
#: lib/string.ex:905 
msgid ""
"Returns a new string padded with a leading filler\n"
"which is made of elements from the `padding`.\n"
"\n"
"Passing a list of strings as `padding` will take one element of the list\n"
"for every missing entry. If the list is shorter than the number of inserts,\n"
"the filling will start again from the beginning of the list.\n"
"Passing a string `padding` is equivalent to passing the list of graphemes in it.\n"
"If no `padding` is given, it defaults to whitespace.\n"
"\n"
"When `count` is less than or equal to the length of `string`,\n"
"given `string` is returned.\n"
"\n"
"Raises `ArgumentError` if the given `padding` contains non-string element.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.pad_leading(\"abc\", 5)\n"
"    \"  abc\"\n"
"\n"
"    iex> String.pad_leading(\"abc\", 4, \"12\")\n"
"    \"1abc\"\n"
"\n"
"    iex> String.pad_leading(\"abc\", 6, \"12\")\n"
"    \"121abc\"\n"
"\n"
"    iex> String.pad_leading(\"abc\", 5, [\"1\", \"23\"])\n"
"    \"123abc\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.equivalent?(string1, string2)
#: lib/string.ex:480 
msgid ""
"Returns `true` if `string1` is canonically equivalent to 'string2'.\n"
"\n"
"It performs Normalization Form Canonical Decomposition (NFD) on the\n"
"strings before comparing them. This function is equivalent to:\n"
"\n"
"    String.normalize(string1, :nfd) == String.normalize(string2, :nfd)\n"
"\n"
"Therefore, if you plan to compare multiple strings, multiple times\n"
"in a row, you may normalize them upfront and compare them directly\n"
"to avoid multiple normalization passes.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.equivalent?(\"abc\", \"abc\")\n"
"    true\n"
"\n"
"    iex> String.equivalent?(\"man\\u0303ana\", \"mañana\")\n"
"    true\n"
"\n"
"    iex> String.equivalent?(\"abc\", \"ABC\")\n"
"    false\n"
"\n"
"    iex> String.equivalent?(\"nø\", \"nó\")\n"
"    false\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.trim_leading(string, to_trim)
#: lib/string.ex:824 
msgid ""
"Returns a string where all leading `to_trim`s have been removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.trim_leading(\"__ abc _\", \"_\")\n"
"    \" abc _\"\n"
"\n"
"    iex> String.trim_leading(\"1 abc\", \"11\")\n"
"    \"1 abc\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.replace_suffix(string, match, replacement)
#: lib/string.ex:749 
msgid ""
"Replaces suffix in `string` by `replacement` if it matches `match`.\n"
"\n"
"Returns the string untouched if there is no match. If `match` is an empty\n"
"string (`\"\"`), `replacement` is just appended to `string`.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.replace_suffix(\"hello\", \" world\", \"\")\n"
"    \"hello\"\n"
"    iex> String.replace_suffix(\"hello world\", \" world\", \"\")\n"
"    \"hello\"\n"
"    iex> String.replace_suffix(\"hello world world\", \" world\", \"\")\n"
"    \"hello world\"\n"
"\n"
"    iex> String.replace_suffix(\"hello\", \" world\", \" mundo\")\n"
"    \"hello\"\n"
"    iex> String.replace_suffix(\"hello world\", \" world\", \" mundo\")\n"
"    \"hello mundo\"\n"
"    iex> String.replace_suffix(\"hello world world\", \" world\", \" mundo\")\n"
"    \"hello world mundo\"\n"
"\n"
"    iex> String.replace_suffix(\"hello\", \"\", \" world\")\n"
"    \"hello world\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.contains?(string, contents)
#: lib/string.ex:1738 
msgid ""
"Checks if `string` contains any of the given `contents`.\n"
"\n"
"`contents` can be either a single string or a list of strings.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.contains? \"elixir of life\", \"of\"\n"
"    true\n"
"    iex> String.contains? \"elixir of life\", [\"life\", \"death\"]\n"
"    true\n"
"    iex> String.contains? \"elixir of life\", [\"death\", \"mercury\"]\n"
"    false\n"
"\n"
"An empty string will always match:\n"
"\n"
"    iex> String.contains? \"elixir of life\", \"\"\n"
"    true\n"
"    iex> String.contains? \"elixir of life\", [\"\", \"other\"]\n"
"    true\n"
"\n"
"The argument can also be a precompiled pattern:\n"
"\n"
"    iex> pattern = :binary.compile_pattern([\"life\", \"death\"])\n"
"    iex> String.contains? \"elixir of life\", pattern\n"
"    true\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.split_at(string, position)
#: lib/string.ex:430 
msgid ""
"Splits a string into two at the specified offset. When the offset given is\n"
"negative, location is counted from the end of the string.\n"
"\n"
"The offset is capped to the length of the string. Returns a tuple with\n"
"two elements.\n"
"\n"
"Note: keep in mind this function splits on graphemes and for such it\n"
"has to linearly traverse the string. If you want to split a string or\n"
"a binary based on the number of bytes, use `Kernel.binary_part/3`\n"
"instead.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.split_at \"sweetelixir\", 5\n"
"    {\"sweet\", \"elixir\"}\n"
"\n"
"    iex> String.split_at \"sweetelixir\", -6\n"
"    {\"sweet\", \"elixir\"}\n"
"\n"
"    iex> String.split_at \"abc\", 0\n"
"    {\"\", \"abc\"}\n"
"\n"
"    iex> String.split_at \"abc\", 1000\n"
"    {\"abc\", \"\"}\n"
"\n"
"    iex> String.split_at \"abc\", -1000\n"
"    {\"\", \"abc\"}\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.duplicate(subject, n)
#: lib/string.ex:1148 
msgid ""
"Returns a string `subject` duplicated `n` times.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.duplicate(\"abc\", 0)\n"
"    \"\"\n"
"\n"
"    iex> String.duplicate(\"abc\", 1)\n"
"    \"abc\"\n"
"\n"
"    iex> String.duplicate(\"abc\", 2)\n"
"    \"abcabc\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.at(string, position)
#: lib/string.ex:1442 
msgid ""
"Returns the grapheme at the `position` of the given UTF-8 `string`.\n"
"If `position` is greater than `string` length, then it returns `nil`.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.at(\"elixir\", 0)\n"
"    \"e\"\n"
"\n"
"    iex> String.at(\"elixir\", 1)\n"
"    \"l\"\n"
"\n"
"    iex> String.at(\"elixir\", 10)\n"
"    nil\n"
"\n"
"    iex> String.at(\"elixir\", -1)\n"
"    \"r\"\n"
"\n"
"    iex> String.at(\"elixir\", -10)\n"
"    nil\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_atom(string)
#: lib/string.ex:1808 
msgid ""
"Converts a string to an atom.\n"
"\n"
"Currently Elixir does not support the conversion of strings\n"
"that contain Unicode codepoints greater than 0xFF.\n"
"\n"
"Inlined by the compiler.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.to_atom(\"my_atom\")\n"
"    :my_atom\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.myers_difference(string1, string2)
#: lib/string.ex:1999 
msgid ""
"Returns a keyword list that represents an edit script.\n"
"\n"
"Check `List.myers_difference/2` for more information.\n"
"\n"
"## Examples\n"
"\n"
"    iex> string1 = \"fox hops over the dog\"\n"
"    iex> string2 = \"fox jumps over the lazy cat\"\n"
"    iex> String.myers_difference(string1, string2)\n"
"    [eq: \"fox \", del: \"ho\", ins: \"jum\", eq: \"ps over the \", del: \"dog\", ins: \"lazy cat\"]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.graphemes(string)
#: lib/string.ex:1319 
msgid ""
"Returns Unicode graphemes in the string as per Extended Grapheme\n"
"Cluster algorithm.\n"
"\n"
"The algorithm is outlined in the [Unicode Standard Annex #29,\n"
"Unicode Text Segmentation](http://www.unicode.org/reports/tr29/).\n"
"\n"
"For details about codepoints and graphemes, see the `String` module documentation.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.graphemes(\"Ńaïve\")\n"
"    [\"Ń\", \"a\", \"ï\", \"v\", \"e\"]\n"
"\n"
"    iex> String.graphemes(\"é\")\n"
"    [\"é\"]\n"
"\n"
"    iex> String.graphemes(\"é\")\n"
"    [\"é\"]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.valid?(string)
#: lib/string.ex:1216 
msgid ""
"Checks whether `string` contains only valid characters.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.valid?(\"a\")\n"
"    true\n"
"\n"
"    iex> String.valid?(\"ø\")\n"
"    true\n"
"\n"
"    iex> String.valid?(<<0xFFFF :: 16>>)\n"
"    false\n"
"\n"
"    iex> String.valid?(\"asd\" <> <<0xFFFF :: 16>>)\n"
"    false\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.trim(string, to_trim)
#: lib/string.ex:888 
msgid ""
"Returns a string where all leading and trailing `to_trim`s have been\n"
"removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.trim(\"a  abc  a\", \"a\")\n"
"    \"  abc  \"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.replace_prefix(string, match, replacement)
#: lib/string.ex:709 
msgid ""
"Replaces prefix in `string` by `replacement` if it matches `match`.\n"
"\n"
"Returns the string untouched if there is no match. If `match` is an empty\n"
"string (`\"\"`), `replacement` is just prepended to `string`.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.replace_prefix(\"world\", \"hello \", \"\")\n"
"    \"world\"\n"
"    iex> String.replace_prefix(\"hello world\", \"hello \", \"\")\n"
"    \"world\"\n"
"    iex> String.replace_prefix(\"hello hello world\", \"hello \", \"\")\n"
"    \"hello world\"\n"
"\n"
"    iex> String.replace_prefix(\"world\", \"hello \", \"ola \")\n"
"    \"world\"\n"
"    iex> String.replace_prefix(\"hello world\", \"hello \", \"ola \")\n"
"    \"ola world\"\n"
"    iex> String.replace_prefix(\"hello hello world\", \"hello \", \"ola \")\n"
"    \"ola hello world\"\n"
"\n"
"    iex> String.replace_prefix(\"world\", \"\", \"hello \")\n"
"    \"hello world\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.split(string, pattern, options \\ [])
#: lib/string.ex:269 
msgid ""
"Divides a string into substrings based on a pattern.\n"
"\n"
"Returns a list of these substrings. The pattern can\n"
"be a string, a list of strings or a regular expression.\n"
"\n"
"The string is split into as many parts as possible by\n"
"default, but can be controlled via the `parts: pos_integer` option.\n"
"If you pass `parts: :infinity`, it will return all possible parts\n"
"(`:infinity` is the default).\n"
"\n"
"Empty strings are only removed from the result if the\n"
"`trim` option is set to `true` (default is `false`).\n"
"\n"
"When the pattern used is a regular expression, the string is\n"
"split using `Regex.split/3`. In that case this function accepts\n"
"additional options which are documented in `Regex.split/3`.\n"
"\n"
"## Examples\n"
"\n"
"Splitting with a string pattern:\n"
"\n"
"    iex> String.split(\"a,b,c\", \",\")\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"    iex> String.split(\"a,b,c\", \",\", parts: 2)\n"
"    [\"a\", \"b,c\"]\n"
"\n"
"    iex> String.split(\" a b c \", \" \", trim: true)\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"A list of patterns:\n"
"\n"
"    iex> String.split(\"1,2 3,4\", [\" \", \",\"])\n"
"    [\"1\", \"2\", \"3\", \"4\"]\n"
"\n"
"A regular expression:\n"
"\n"
"    iex> String.split(\"a,b,c\", ~r{,})\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"    iex> String.split(\"a,b,c\", ~r{,}, parts: 2)\n"
"    [\"a\", \"b,c\"]\n"
"\n"
"    iex> String.split(\" a b c \", ~r{\\s}, trim: true)\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"    iex> String.split(\"abc\", ~r{b}, include_captures: true)\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"Splitting on empty patterns returns graphemes:\n"
"\n"
"    iex> String.split(\"abc\", ~r{})\n"
"    [\"a\", \"b\", \"c\", \"\"]\n"
"\n"
"    iex> String.split(\"abc\", \"\")\n"
"    [\"a\", \"b\", \"c\", \"\"]\n"
"\n"
"    iex> String.split(\"abc\", \"\", trim: true)\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"    iex> String.split(\"abc\", \"\", parts: 2)\n"
"    [\"a\", \"bc\"]\n"
"\n"
"A precompiled pattern can also be given:\n"
"\n"
"    iex> pattern = :binary.compile_pattern([\" \", \",\"])\n"
"    iex> String.split(\"1,2 3,4\", pattern)\n"
"    [\"1\", \"2\", \"3\", \"4\"]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.slice(string, start, len)
#: lib/string.ex:1485 
msgid ""
"Returns a substring starting at the offset `start`, and of\n"
"length `len`.\n"
"\n"
"If the offset is greater than string length, then it returns `\"\"`.\n"
"\n"
"Remember this function works with Unicode graphemes and considers\n"
"the slices to represent grapheme offsets. If you want to split\n"
"on raw bytes, check `Kernel.binary_part/3` instead.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.slice(\"elixir\", 1, 3)\n"
"    \"lix\"\n"
"\n"
"    iex> String.slice(\"elixir\", 1, 10)\n"
"    \"lixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", 10, 3)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"elixir\", -4, 4)\n"
"    \"ixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", -10, 3)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"a\", 0, 1500)\n"
"    \"a\"\n"
"\n"
"    iex> String.slice(\"a\", 1, 1500)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"a\", 2, 1500)\n"
"    \"\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.next_codepoint(string)
#: lib/string.ex:1194 
msgid ""
"Returns the next codepoint in a string.\n"
"\n"
"The result is a tuple with the codepoint and the\n"
"remainder of the string or `nil` in case\n"
"the string reached its end.\n"
"\n"
"As with other functions in the String module, this\n"
"function does not check for the validity of the codepoint.\n"
"That said, if an invalid codepoint is found, it will\n"
"be returned by this function.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.next_codepoint(\"olá\")\n"
"    {\"o\", \"lá\"}\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.trim_leading(string)
#: lib/string.ex:811 
msgid ""
"Returns a string where all leading Unicode whitespaces\n"
"have been removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.trim_leading(\"\\n  abc   \")\n"
"    \"abc   \"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.downcase(binary)
#: lib/string.ex:558 
msgid ""
"Converts all characters in the given string to lowercase.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.downcase(\"ABCD\")\n"
"    \"abcd\"\n"
"\n"
"    iex> String.downcase(\"AB 123 XPTO\")\n"
"    \"ab 123 xpto\"\n"
"\n"
"    iex> String.downcase(\"OLÁ\")\n"
"    \"olá\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.length(string)
#: lib/string.ex:1427 
msgid ""
"Returns the number of Unicode graphemes in a UTF-8 string.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.length(\"elixir\")\n"
"    6\n"
"\n"
"    iex> String.length(\"եոգլի\")\n"
"    5\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.starts_with?(string, prefix)
#: lib/string.ex:1644 
msgid ""
"Returns `true` if `string` starts with any of the prefixes given.\n"
"\n"
"`prefix` can be either a single prefix or a list of prefixes.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.starts_with? \"elixir\", \"eli\"\n"
"    true\n"
"    iex> String.starts_with? \"elixir\", [\"erlang\", \"elixir\"]\n"
"    true\n"
"    iex> String.starts_with? \"elixir\", [\"erlang\", \"ruby\"]\n"
"    false\n"
"\n"
"An empty string will always match:\n"
"\n"
"    iex> String.starts_with? \"elixir\", \"\"\n"
"    true\n"
"    iex> String.starts_with? \"elixir\", [\"\", \"other\"]\n"
"    true\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_charlist(string)
#: lib/string.ex:1779 
msgid ""
"Converts a string into a charlist.\n"
"\n"
"Specifically, this functions takes a UTF-8 encoded binary and returns a list of its integer\n"
"codepoints. It is similar to `codepoints/1` except that the latter returns a list of codepoints as\n"
"strings.\n"
"\n"
"In case you need to work with bytes, take a look at the\n"
"[`:binary` module](http://www.erlang.org/doc/man/binary.html).\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.to_charlist(\"æß\")\n"
"    'æß'\n"
msgstr ""
#. TRANSLATORS: def String.next_grapheme(binary)
#: lib/string.ex:1345 
msgid ""
"Returns the next grapheme in a string.\n"
"\n"
"The result is a tuple with the grapheme and the\n"
"remainder of the string or `nil` in case\n"
"the String reached its end.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.next_grapheme(\"olá\")\n"
"    {\"o\", \"lá\"}\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_existing_atom(string)
#: lib/string.ex:1827 
msgid ""
"Converts a string to an existing atom.\n"
"\n"
"Currently Elixir does not support the conversion of strings\n"
"that contain Unicode codepoints greater than 0xFF.\n"
"\n"
"Inlined by the compiler.\n"
"\n"
"## Examples\n"
"\n"
"    iex> _ = :my_atom\n"
"    iex> String.to_existing_atom(\"my_atom\")\n"
"    :my_atom\n"
"\n"
"    iex> String.to_existing_atom(\"this_atom_will_never_exist\")\n"
"    ** (ArgumentError) argument error\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.printable?(string)
#: lib/string.ex:208 
msgid ""
"Checks if a string contains only printable characters.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.printable?(\"abc\")\n"
"    true\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.jaro_distance(string1, string2)
#: lib/string.ex:1906 
msgid ""
"Returns a float value between 0 (equates to no similarity) and 1 (is an exact match)\n"
"representing [Jaro](https://en.wikipedia.org/wiki/Jaro–Winkler_distance)\n"
"distance between `string1` and `string2`.\n"
"\n"
"The Jaro distance metric is designed and best suited for short strings such as person names.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.jaro_distance(\"dwayne\", \"duane\")\n"
"    0.8222222222222223\n"
"    iex> String.jaro_distance(\"even\", \"odd\")\n"
"    0.0\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.trim(string)
#: lib/string.ex:871 
msgid ""
"Returns a string where all leading and trailing Unicode whitespaces\n"
"have been removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.trim(\"\\n  abc\\n  \")\n"
"    \"abc\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_integer(string, base)
#: lib/string.ex:1866 
msgid ""
"Returns an integer whose text representation is `string` in base `base`.\n"
"\n"
"Inlined by the compiler.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.to_integer(\"3FF\", 16)\n"
"    1023\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.replace(subject, pattern, replacement, options \\ [])
#: lib/string.ex:1037 
msgid ""
"Returns a new string created by replacing occurrences of `pattern` in\n"
"`subject` with `replacement`.\n"
"\n"
"By default, it replaces all occurrences, unless the `global` option is\n"
"set to `false`, where it will only replace the first one\n"
"\n"
"The `pattern` may be a string or a regular expression.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.replace(\"a,b,c\", \",\", \"-\")\n"
"    \"a-b-c\"\n"
"\n"
"    iex> String.replace(\"a,b,c\", \",\", \"-\", global: false)\n"
"    \"a-b,c\"\n"
"\n"
"When the pattern is a regular expression, one can give `\\N` or\n"
"`\\g{N}` in the `replacement` string to access a specific capture in the\n"
"regular expression:\n"
"\n"
"    iex> String.replace(\"a,b,c\", ~r/,(.)/, \",\\\\1\\\\g{1}\")\n"
"    \"a,bb,cc\"\n"
"\n"
"Notice we had to escape the backslash escape character (i.e., we used `\\\\N`\n"
"instead of just `\\N` to escape the backslash; same thing for `\\\\g{N}`). By\n"
"giving `\\0`, one can inject the whole matched pattern in the replacement\n"
"string.\n"
"\n"
"When the pattern is a string, a developer can use the replaced part inside\n"
"the `replacement` by using the `:insert_replaced` option and specifying the\n"
"position(s) inside the `replacement` where the string pattern will be\n"
"inserted:\n"
"\n"
"    iex> String.replace(\"a,b,c\", \"b\", \"[]\", insert_replaced: 1)\n"
"    \"a,[b],c\"\n"
"\n"
"    iex> String.replace(\"a,b,c\", \",\", \"[]\", insert_replaced: 2)\n"
"    \"a[],b[],c\"\n"
"\n"
"    iex> String.replace(\"a,b,c\", \",\", \"[]\", insert_replaced: [1, 1])\n"
"    \"a[,,]b[,,]c\"\n"
"\n"
"If any position given in the `:insert_replaced` option is larger than the\n"
"replacement string, or is negative, an `ArgumentError` is raised.\n"
msgstr ""
#. TRANSLATORS: def String.match?(string, regex)
#: lib/string.ex:1721 
msgid ""
"Checks if `string` matches the given regular expression.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.match?(\"foo\", ~r/foo/)\n"
"    true\n"
"\n"
"    iex> String.match?(\"bar\", ~r/foo/)\n"
"    false\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.codepoints(string)
#: lib/string.ex:1168 
msgid ""
"Returns all codepoints in the string.\n"
"\n"
"For details about codepoints and graphemes, see the `String` module documentation.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.codepoints(\"olá\")\n"
"    [\"o\", \"l\", \"á\"]\n"
"\n"
"    iex> String.codepoints(\"оптими зации\")\n"
"    [\"о\", \"п\", \"т\", \"и\", \"м\", \"и\", \" \", \"з\", \"а\", \"ц\", \"и\", \"и\"]\n"
"\n"
"    iex> String.codepoints(\"ἅἪῼ\")\n"
"    [\"ἅ\", \"Ἢ\", \"ῼ\"]\n"
"\n"
"    iex> String.codepoints(\"é\")\n"
"    [\"é\"]\n"
"\n"
"    iex> String.codepoints(\"é\")\n"
"    [\"e\", \"́\"]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.split(binary)
#: lib/string.ex:245 
msgid ""
"Divides a string into substrings at each Unicode whitespace\n"
"occurrence with leading and trailing whitespace ignored. Groups\n"
"of whitespace are treated as a single occurrence. Divisions do\n"
"not occur on non-breaking whitespace.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.split(\"foo bar\")\n"
"    [\"foo\", \"bar\"]\n"
"\n"
"    iex> String.split(\"foo\" <> <<194, 133>> <> \"bar\")\n"
"    [\"foo\", \"bar\"]\n"
"\n"
"    iex> String.split(\" foo   bar \")\n"
"    [\"foo\", \"bar\"]\n"
"\n"
"    iex> String.split(\"no\\u00a0break\")\n"
"    [\"no\\u00a0break\"]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.trim_trailing(string, to_trim)
#: lib/string.ex:854 
msgid ""
"Returns a string where all trailing `to_trim`s have been removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.trim_trailing(\"_ abc __\", \"_\")\n"
"    \"_ abc \"\n"
"\n"
"    iex> String.trim_trailing(\"abc 1\", \"11\")\n"
"    \"abc 1\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.trim_trailing(string)
#: lib/string.ex:841 
msgid ""
"Returns a string where all trailing Unicode whitespaces\n"
"has been removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.trim_trailing(\"   abc\\n  \")\n"
"    \"   abc\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.replace_leading(string, match, replacement)
#: lib/string.ex:613 
msgid ""
"Replaces all leading occurrences of `match` by `replacement` of `match` in `string`.\n"
"\n"
"Returns the string untouched if there are no occurrences.\n"
"\n"
"If `match` is `\"\"`, this function raises an `ArgumentError` exception: this\n"
"happens because this function replaces **all** the occurrences of `match` at\n"
"the beginning of `string`, and it's impossible to replace \"multiple\"\n"
"occurrences of `\"\"`.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.replace_leading(\"hello world\", \"hello \", \"\")\n"
"    \"world\"\n"
"    iex> String.replace_leading(\"hello hello world\", \"hello \", \"\")\n"
"    \"world\"\n"
"\n"
"    iex> String.replace_leading(\"hello world\", \"hello \", \"ola \")\n"
"    \"ola world\"\n"
"    iex> String.replace_leading(\"hello hello world\", \"hello \", \"ola \")\n"
"    \"ola ola world\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_integer(string)
#: lib/string.ex:1850 
msgid ""
"Returns an integer whose text representation is `string`.\n"
"\n"
"Inlined by the compiler.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.to_integer(\"123\")\n"
"    123\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.replace_trailing(string, match, replacement)
#: lib/string.ex:661 
msgid ""
"Replaces all trailing occurrences of `match` by `replacement` in `string`.\n"
"\n"
"Returns the string untouched if there are no occurrences.\n"
"\n"
"If `match` is `\"\"`, this function raises an `ArgumentError` exception: this\n"
"happens because this function replaces **all** the occurrences of `match` at\n"
"the end of `string`, and it's impossible to replace \"multiple\" occurrences of\n"
"`\"\"`.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.replace_trailing(\"hello world\", \" world\", \"\")\n"
"    \"hello\"\n"
"    iex> String.replace_trailing(\"hello world world\", \" world\", \"\")\n"
"    \"hello\"\n"
"\n"
"    iex> String.replace_trailing(\"hello world\", \" world\", \" mundo\")\n"
"    \"hello mundo\"\n"
"    iex> String.replace_trailing(\"hello world world\", \" world\", \" mundo\")\n"
"    \"hello mundo mundo\"\n"
"\n"
msgstr ""
#. TRANSLATORS: Elixir.String Summary
#: lib/string.ex:4 
msgid ""
"A String in Elixir is a UTF-8 encoded binary.\n"
"\n"
"## Codepoints and grapheme cluster\n"
"\n"
"The functions in this module act according to the Unicode\n"
"Standard, version 9.0.0.\n"
"\n"
"As per the standard, a codepoint is a single Unicode Character,\n"
"which may be represented by one or more bytes.\n"
"\n"
"For example, the codepoint \"é\" is two bytes:\n"
"\n"
"    iex> byte_size(\"é\")\n"
"    2\n"
"\n"
"However, this module returns the proper length:\n"
"\n"
"    iex> String.length(\"é\")\n"
"    1\n"
"\n"
"Furthermore, this module also presents the concept of grapheme cluster\n"
"(from now on referenced as graphemes). Graphemes can consist of multiple\n"
"codepoints that may be perceived as a single character by readers. For\n"
"example, \"é\" can be represented either as a single \"e with acute\" codepoint\n"
"or as the letter \"e\" followed by a \"combining acute accent\" (two codepoints):\n"
"\n"
"    iex> string = \"\\u0065\\u0301\"\n"
"    iex> byte_size(string)\n"
"    3\n"
"    iex> String.length(string)\n"
"    1\n"
"    iex> String.codepoints(string)\n"
"    [\"e\", \"́\"]\n"
"    iex> String.graphemes(string)\n"
"    [\"é\"]\n"
"\n"
"Although the example above is made of two characters, it is\n"
"perceived by users as one.\n"
"\n"
"Graphemes can also be two characters that are interpreted\n"
"as one by some languages. For example, some languages may\n"
"consider \"ch\" as a single character. However, since this\n"
"information depends on the locale, it is not taken into account\n"
"by this module.\n"
"\n"
"In general, the functions in this module rely on the Unicode\n"
"Standard, but do not contain any of the locale specific behaviour.\n"
"\n"
"More information about graphemes can be found in the [Unicode\n"
"Standard Annex #29](http://www.unicode.org/reports/tr29/).\n"
"The current Elixir version implements Extended Grapheme Cluster\n"
"algorithm.\n"
"\n"
"## String and binary operations\n"
"\n"
"To act according to the Unicode Standard, many functions\n"
"in this module run in linear time, as they need to traverse\n"
"the whole string considering the proper Unicode codepoints.\n"
"\n"
"For example, `String.length/1` will take longer as\n"
"the input grows. On the other hand, `Kernel.byte_size/1` always runs\n"
"in constant time (i.e. regardless of the input size).\n"
"\n"
"This means often there are performance costs in using the\n"
"functions in this module, compared to the more low-level\n"
"operations that work directly with binaries:\n"
"\n"
"  * `Kernel.binary_part/3` - retrieves part of the binary\n"
"  * `Kernel.bit_size/1` and `Kernel.byte_size/1` - size related functions\n"
"  * `Kernel.is_bitstring/1` and `Kernel.is_binary/1` - type checking function\n"
"  * Plus a number of functions for working with binaries (bytes)\n"
"    in the [`:binary` module](http://www.erlang.org/doc/man/binary.html)\n"
"\n"
"There are many situations where using the `String` module can\n"
"be avoided in favor of binary functions or pattern matching.\n"
"For example, imagine you have a string `prefix` and you want to\n"
"remove this prefix from another string named `full`.\n"
"\n"
"One may be tempted to write:\n"
"\n"
"    iex> take_prefix = fn full, prefix ->\n"
"    ...>   base = String.length(prefix)\n"
"    ...>   String.slice(full, base, String.length(full) - base)\n"
"    ...> end\n"
"    iex> take_prefix.(\"Mr. John\", \"Mr. \")\n"
"    \"John\"\n"
"\n"
"Although the function above works, it performs poorly. To\n"
"calculate the length of the string, we need to traverse it\n"
"fully, so we traverse both `prefix` and `full` strings, then\n"
"slice the `full` one, traversing it again.\n"
"\n"
"A first attempt at improving it could be with ranges:\n"
"\n"
"    iex> take_prefix = fn full, prefix ->\n"
"    ...>   base = String.length(prefix)\n"
"    ...>   String.slice(full, base..-1)\n"
"    ...> end\n"
"    iex> take_prefix.(\"Mr. John\", \"Mr. \")\n"
"    \"John\"\n"
"\n"
"While this is much better (we don't traverse `full` twice),\n"
"it could still be improved. In this case, since we want to\n"
"extract a substring from a string, we can use `Kernel.byte_size/1`\n"
"and `Kernel.binary_part/3` as there is no chance we will slice in\n"
"the middle of a codepoint made of more than one byte:\n"
"\n"
"    iex> take_prefix = fn full, prefix ->\n"
"    ...>   base = byte_size(prefix)\n"
"    ...>   binary_part(full, base, byte_size(full) - base)\n"
"    ...> end\n"
"    iex> take_prefix.(\"Mr. John\", \"Mr. \")\n"
"    \"John\"\n"
"\n"
"Or simply use pattern matching:\n"
"\n"
"    iex> take_prefix = fn full, prefix ->\n"
"    ...>   base = byte_size(prefix)\n"
"    ...>   <<_::binary-size(base), rest::binary>> = full\n"
"    ...>   rest\n"
"    ...> end\n"
"    iex> take_prefix.(\"Mr. John\", \"Mr. \")\n"
"    \"John\"\n"
"\n"
"On the other hand, if you want to dynamically slice a string\n"
"based on an integer value, then using `String.slice/3` is the\n"
"best option as it guarantees we won't incorrectly split a valid\n"
"codepoint into multiple bytes.\n"
"\n"
"## Integer codepoints\n"
"\n"
"Although codepoints could be represented as integers, this\n"
"module represents all codepoints as strings. For example:\n"
"\n"
"    iex> String.codepoints(\"olá\")\n"
"    [\"o\", \"l\", \"á\"]\n"
"\n"
"There are a couple of ways to retrieve a character integer\n"
"codepoint. One may use the `?` construct:\n"
"\n"
"    iex> ?o\n"
"    111\n"
"\n"
"    iex> ?á\n"
"    225\n"
"\n"
"Or also via pattern matching:\n"
"\n"
"    iex> <<aacute::utf8>> = \"á\"\n"
"    iex> aacute\n"
"    225\n"
"\n"
"As we have seen above, codepoints can be inserted into\n"
"a string by their hexadecimal code:\n"
"\n"
"    \"ol\\u0061\\u0301\" #=>\n"
"    \"olá\"\n"
"\n"
"## Self-synchronization\n"
"\n"
"The UTF-8 encoding is self-synchronizing. This means that\n"
"if malformed data (i.e., data that is not possible according\n"
"to the definition of the encoding) is encountered, only one\n"
"codepoint needs to be rejected.\n"
"\n"
"This module relies on this behaviour to ignore such invalid\n"
"characters. For example, `length/1` will return\n"
"a correct result even if an invalid codepoint is fed into it.\n"
"\n"
"In other words, this module expects invalid data to be detected\n"
"elsewhere, usually when retrieving data from the external source.\n"
"For example, a driver that reads strings from a database will be\n"
"responsible to check the validity of the encoding. `String.chunk/2`\n"
"can be used for breaking a string into valid and invalid parts.\n"
"\n"
"## Patterns\n"
"\n"
"Many functions in this module work with patterns. For example,\n"
"`String.split/2` can split a string into multiple patterns given\n"
"a pattern. This pattern can be a string, a list of strings or\n"
"a compiled pattern:\n"
"\n"
"    iex> String.split(\"foo bar\", \" \")\n"
"    [\"foo\", \"bar\"]\n"
"\n"
"    iex> String.split(\"foo bar!\", [\" \", \"!\"])\n"
"    [\"foo\", \"bar\", \"\"]\n"
"\n"
"    iex> pattern = :binary.compile_pattern([\" \", \"!\"])\n"
"    iex> String.split(\"foo bar!\", pattern)\n"
"    [\"foo\", \"bar\", \"\"]\n"
"\n"
"The compiled pattern is useful when the same match will\n"
"be done over and over again. Note though the compiled\n"
"pattern cannot be stored in a module attribute as the pattern\n"
"is generated at runtime and does not survive compile term.\n"
msgstr ""
